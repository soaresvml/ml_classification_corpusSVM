{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/svncjus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/svncjus/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/svncjus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter, attrgetter\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "nltk.download(['stopwords','rslp','punkt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(features, labels, folds):\n",
    "  print('Linear SVM start: ')\n",
    "  clf = svm.SVC(kernel='linear', C=1)\n",
    "  predict = cross_val_predict(clf, features, labels, cv=folds)\n",
    "  cm = confusion_matrix(labels, predict)\n",
    "  print(cm)\n",
    "  print(classification_report(labels, predict, target_names=np.unique(labels)))\n",
    "  print('----------------------------------------------')\n",
    "  return predict, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(filename, stopwords, steemer):\n",
    "  f = open(filename, \"r\", encoding=\"utf-8-sig\")\n",
    "  data = []\n",
    "  while True:\n",
    "      chunk = f.readline() #pega linha do arquivo\n",
    "      if chunk == '': #verifica se arquivo acabou\n",
    "          break\n",
    "      text = chunk.split(';;') #divide em classe (text[0]) e texto (text[1])\n",
    "      \n",
    "      tokens = nltk.word_tokenize(text[1]) #tokeniza a linha\n",
    "      tokensLimpo = []\n",
    "      for palavra in tokens:\n",
    "          if (palavra not in stopwords):\n",
    "              tokensLimpo.append(stemmer.stem(palavra)) #insere na lista de tokens limpos o steemer da palavra\n",
    "      instance = (text[0],tokensLimpo) #cria uma instancia \n",
    "      data.append(instance)\n",
    "\n",
    "  #-------------- BoW -------------------\n",
    "  #Elenca tokens unicos\n",
    "  allwords = []\n",
    "  for text in data:\n",
    "      for word in text[1]:\n",
    "          if word not in allwords:\n",
    "              allwords.append(word)  \n",
    "  allwords.sort() #ordena tokens\n",
    "\n",
    "  #gera Matriz de ocorrências de palavras\n",
    "  qtdPalavras = len(allwords)\n",
    "  features = []\n",
    "  labels = []\n",
    "  for texto in data:\n",
    "      ocorrencias = []\n",
    "      labels.append(texto[0])\n",
    "      for palavra in allwords:\n",
    "          if palavra in texto[1]:\n",
    "              ocorrencias.append(texto[1].count(palavra))\n",
    "          else:\n",
    "              ocorrencias.append(0)\n",
    "      features.append(ocorrencias)\n",
    "\n",
    "  return labels, features, allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista StopWords\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese') #carrega stopwords da lingua portuguesa disponíveis no NLTK\n",
    "stopwords+= (',','.','(',')','\"',\"'\",'´','`','!','$','%','&','...','-',':',';','?','``','\\'\\'') #acrescenta simbolos\n",
    "stopwords+= ('a','e','i','o','u','A','E','I','O','U') #acrescenta também vogais\n",
    "#Stemmer PTBR\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFile = \"2000_textos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels7, features7, allwords7 = loadFile(InputFile, stopwords, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Instâncias 7 classes: 2000\n",
      "Features 7 classes: 6658\n",
      "Linear SVM start: \n",
      "[[ 37  13   7  80   2  27  18]\n",
      " [  8 101  18  80   7  13  35]\n",
      " [  6  18 103  22   4  16  53]\n",
      " [ 41  57   8 389   1  21  25]\n",
      " [  3  13   8   7  22   7  23]\n",
      " [ 24  29  15  39   4 121  20]\n",
      " [ 18  41  43  34  16  24 279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     alegria       0.27      0.20      0.23       184\n",
      "    desgosto       0.37      0.39      0.38       262\n",
      "        medo       0.51      0.46      0.49       222\n",
      "      neutro       0.60      0.72      0.65       542\n",
      "       raiva       0.39      0.27      0.32        83\n",
      "    surpresa       0.53      0.48      0.50       252\n",
      "    tristeza       0.62      0.61      0.61       455\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.47      0.45      0.45      2000\n",
      "weighted avg       0.52      0.53      0.52      2000\n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------') \n",
    "print(\"Instâncias 7 classes: \"+str(len(labels7)))\n",
    "print(\"Features 7 classes: \"+str(len(features7[0])))\n",
    "\n",
    "predict7, cm7 = SVM(features7, labels7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alegria',\n",
       " 'tristeza',\n",
       " 'surpresa',\n",
       " 'tristeza',\n",
       " 'neutro',\n",
       " 'neutro',\n",
       " 'tristeza',\n",
       " 'raiva',\n",
       " 'surpresa',\n",
       " 'surpresa']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels7[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile2(filename, stopwords, steemer):\n",
    "  f = open(filename, \"r\", encoding=\"utf-8-sig\")\n",
    "  data = []\n",
    "  while True:\n",
    "      chunk = f.readline() #pega linha do arquivo\n",
    "      if chunk == '': #verifica se arquivo acabou\n",
    "          break\n",
    "      text = chunk.split(';;') #divide em classe (text[0]) e texto (text[1])\n",
    "      \n",
    "      tokens = nltk.word_tokenize(text[1]) #tokeniza a linha\n",
    "      tokensLimpo = []\n",
    "      for palavra in tokens:\n",
    "          if (palavra not in stopwords):\n",
    "              tokensLimpo.append(stemmer.stem(palavra)) #insere na lista de tokens limpos o steemer da palavra\n",
    "      instance = (text[0],tokensLimpo) #cria uma instancia \n",
    "      data.append(instance)\n",
    "\n",
    "  #-------------- BoW -------------------\n",
    "  #Elenca tokens unicos\n",
    "  allwords = []\n",
    "  for text in data:\n",
    "      for word in text[1]:\n",
    "          if word not in allwords:\n",
    "              allwords.append(word)  \n",
    "  allwords.sort() #ordena tokens\n",
    "\n",
    "  #gera Matriz de ocorrências de palavras\n",
    "  qtdPalavras = len(allwords)\n",
    "  features = []\n",
    "  labels = []\n",
    "  for texto in data:\n",
    "    ocorrencias = []\n",
    "    #transformação das labels para redução de granularidade\n",
    "    if texto[0]==\"alegria\":\n",
    "        labels.append(\"positivo\")\n",
    "    elif texto[0] in (\"raiva\",\"medo\",\"desgosto\",\"tristeza\"):\n",
    "        labels.append(\"negativo\")\n",
    "    elif texto[0] == \"surpresa\":\n",
    "        continue\n",
    "    else:\n",
    "        labels.append(texto[0])\n",
    "    for palavra in allwords:\n",
    "        #adição do condicional para não incluir instâncias classificadas como \"surpresa\"\n",
    "        if palavra in texto[1] and texto[0] != \"surpresa\":\n",
    "            ocorrencias.append(texto[1].count(palavra))\n",
    "        else:\n",
    "            ocorrencias.append(0)\n",
    "    features.append(ocorrencias)\n",
    "\n",
    "  return labels, features, allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels3, features3, allwords3 = loadFile2(InputFile, stopwords, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'positivo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'neutro',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'neutro',\n",
       " 'positivo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'neutro',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'negativo',\n",
       " 'positivo',\n",
       " 'negativo']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels3[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Instâncias 3 classes: 1748\n",
      "Features 3 classes: 6658\n",
      "Linear SVM start: \n",
      "[[880 125  17]\n",
      " [161 354  27]\n",
      " [ 64  74  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.80      0.86      0.83      1022\n",
      "      neutro       0.64      0.65      0.65       542\n",
      "    positivo       0.51      0.25      0.34       184\n",
      "\n",
      "    accuracy                           0.73      1748\n",
      "   macro avg       0.65      0.59      0.60      1748\n",
      "weighted avg       0.72      0.73      0.72      1748\n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------') \n",
    "print(\"Instâncias 3 classes: \"+str(len(labels3)))\n",
    "print(\"Features 3 classes: \"+str(len(features3[0])))\n",
    "\n",
    "predict3, cm3 = SVM(features3, labels3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "De Acordo com o previsto, a exclusão da categoria \"surpresa\" e a redução da dimensionalidade das classes, provocou um aumento expressivo na performance do modelo preditivo conforme podemos perceber no relatório acima. A precisão avançou quase 30 p.p, recall e f1-score quase 20 p.p."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
